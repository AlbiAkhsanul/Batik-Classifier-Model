{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()\n",
    "datasets_path = os.getenv('AUGMENTED_PATH_JOGJA_PEKALONGAN')\n",
    "models_path = os.getenv('MODELS_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jogja', 'pekalongan']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 16\n",
    "test_split_ratio = 0.2\n",
    "val_split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset With GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "class GLCMCNNHybridDataset(Dataset):\n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "        # Simpan fitur GLCM dan label\n",
    "        self.glcm_features = []\n",
    "        self.labels = []\n",
    "\n",
    "        print(\"ðŸ”„ Preprocessing GLCM features...\")\n",
    "\n",
    "        for idx in range(len(image_folder_dataset)):\n",
    "            image, label = image_folder_dataset[idx]\n",
    "\n",
    "            # Simpan label\n",
    "            self.labels.append(label)\n",
    "\n",
    "            # Transform dulu (pakai transform yg sama dengan training)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # Convert tensor (C, H, W) -> numpy image (H, W, C)\n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            image_np = (image_np * 255).astype(np.uint8)\n",
    "\n",
    "            # Ekstrak GLCM\n",
    "            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "            distances = [1, 2, 3]\n",
    "            angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "            glcm = graycomatrix(gray, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "            props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "            features = []\n",
    "            for prop in props:\n",
    "                values = graycoprops(glcm, prop)\n",
    "                features.extend(values.flatten())\n",
    "            features = np.array(features, dtype=np.float32)\n",
    "\n",
    "            # Normalisasi fitur (z-score)\n",
    "            features = (features - features.mean()) / (features.std() + 1e-8)\n",
    "            self.glcm_features.append(features)\n",
    "\n",
    "        # Konversi list ke tensor\n",
    "        self.glcm_features = torch.tensor(np.array(self.glcm_features), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
    "\n",
    "        print(\"âœ… GLCM features extracted and cached.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, _ = self.image_folder_dataset[index]  # label diambil dari self.labels\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        glcm_feature = self.glcm_features[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return image, glcm_feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preprocessing GLCM features...\n",
      "âœ… GLCM features extracted and cached.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Buat dataset dasar\n",
    "base_dataset = datasets.ImageFolder(root=datasets_path)\n",
    "hybrid_dataset = GLCMCNNHybridDataset(base_dataset, transform=transform)\n",
    "\n",
    "# Ambil semua label\n",
    "targets = base_dataset.targets\n",
    "indices = list(range(len(base_dataset)))\n",
    "\n",
    "# Pertama: Bagi data menjadi train+val dan test\n",
    "trainval_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=test_split_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ambil label untuk data trainval\n",
    "trainval_targets = [targets[i] for i in trainval_indices]\n",
    "\n",
    "# Kedua: Bagi trainval menjadi train dan val\n",
    "train_indices, val_indices = train_test_split(\n",
    "    trainval_indices,\n",
    "    test_size=val_split_ratio,\n",
    "    stratify=trainval_targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Buat subset dataset-nya\n",
    "train_dataset = Subset(hybrid_dataset, train_indices)\n",
    "val_dataset = Subset(hybrid_dataset, val_indices)\n",
    "test_dataset = Subset(hybrid_dataset, test_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape GLCM Features: torch.Size([16, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cek dimensi glcm_features\n",
    "for images, glcm_features, labels in train_loader:\n",
    "    print(\"Shape GLCM Features:\", glcm_features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas (train): Counter({0: 307, 1: 307})\n",
      "Distribusi kelas (test): Counter({1: 96, 0: 96})\n",
      "Distribusi kelas (val): Counter({0: 77, 1: 77})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Distribusi kelas (train):\", Counter([base_dataset.targets[i] for i in train_indices]))\n",
    "print(\"Distribusi kelas (test):\", Counter([base_dataset.targets[i] for i in test_indices]))\n",
    "print(\"Distribusi kelas (val):\", Counter([base_dataset.targets[i] for i in val_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model (EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet-B0\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "cnn_model = efficientnet_b0(weights=weights)\n",
    "cnn_feature_size = cnn_model.classifier[1].in_features  # EfficientNet features\n",
    "\n",
    "# Replace classification layer to get features\n",
    "cnn_model.classifier = nn.Identity()\n",
    "cnn_model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(cnn_feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PararelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(PararelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParallelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(SimpleParallelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 256)  # Menurunkan dimensi\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Langsung ke output class\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_feature_size = 60  # Number of GLCM features\n",
    "# model = PararelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)\n",
    "model = SimpleParallelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\albia\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.2563, Val Acc: 0.9792\n",
      "Epoch [2/50], Loss: 0.1087, Val Acc: 0.9896\n",
      "Epoch [3/50], Loss: 0.1454, Val Acc: 0.9010\n",
      "Epoch [4/50], Loss: 0.1365, Val Acc: 0.9375\n",
      "Epoch [5/50], Loss: 0.1085, Val Acc: 0.9792\n",
      "Epoch [6/50], Loss: 0.0884, Val Acc: 0.9792\n",
      "Epoch [7/50], Loss: 0.0974, Val Acc: 0.9271\n",
      "Epoch [8/50], Loss: 0.0817, Val Acc: 0.9792\n",
      "Epoch [9/50], Loss: 0.0467, Val Acc: 0.9896\n",
      "Epoch [10/50], Loss: 0.0266, Val Acc: 0.9896\n",
      "Epoch [11/50], Loss: 0.0516, Val Acc: 0.9896\n",
      "Epoch [12/50], Loss: 0.1369, Val Acc: 0.9635\n",
      "Epoch [13/50], Loss: 0.3416, Val Acc: 0.9792\n",
      "Epoch [14/50], Loss: 0.0803, Val Acc: 0.9792\n",
      "Epoch [15/50], Loss: 0.0930, Val Acc: 1.0000\n",
      "â›” Early stopping triggered at epoch 15\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "patience = 5  # jumlah epoch tanpa perbaikan sebelum berhenti\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0015\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, glcm_features, labels in data_loader:\n",
    "            images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "            outputs = model(images, glcm_features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Training loop dengan early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, glcm_features, labels in train_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, glcm_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    val_acc = evaluate(model, test_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if epoch_loss < best_loss - 1e-4:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'temp/best_model_hybrid.pth')  # Simpan model terbaik\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"â›” Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        96\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       192\n",
      "   macro avg       1.00      1.00      1.00       192\n",
      "weighted avg       1.00      1.00      1.00       192\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, glcm_features, labels in test_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "        outputs = model(images, glcm_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Hitung precision, recall, f1 untuk setiap kelas\n",
    "precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "\n",
    "# Tampilkan nilai precision, recall, dan f1-score per kelas\n",
    "num_classes = len(set(all_labels))  # Jumlah kelas yang ada di dataset\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall:    {recall[i]:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1[i]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Tampilkan classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), models_path+'/hybrid_glcm_cnn_modelv2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
