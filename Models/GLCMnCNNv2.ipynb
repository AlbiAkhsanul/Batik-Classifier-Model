{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()\n",
    "datasets_path = os.getenv('AUGMENTED_SMALL_PATH_JOGJA_PEKALONGAN')\n",
    "models_path = os.getenv('MODELS_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jogja', 'pekalongan']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 16\n",
    "test_split_ratio = 0.2\n",
    "val_split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset With GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "class GLCMCNNHybridDataset(Dataset):\n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "        # Simpan fitur GLCM dan label\n",
    "        self.glcm_features = []\n",
    "        self.labels = []\n",
    "\n",
    "        print(\"ðŸ”„ Preprocessing GLCM features...\")\n",
    "\n",
    "        for idx in range(len(image_folder_dataset)):\n",
    "            image, label = image_folder_dataset[idx]\n",
    "\n",
    "            # Simpan label\n",
    "            self.labels.append(label)\n",
    "\n",
    "            # Transform dulu (pakai transform yg sama dengan training)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # Convert tensor (C, H, W) -> numpy image (H, W, C)\n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            image_np = (image_np * 255).astype(np.uint8)\n",
    "\n",
    "            # Ekstrak GLCM\n",
    "            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "            distances = [1, 2, 3]\n",
    "            angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "            glcm = graycomatrix(gray, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "            props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "            features = []\n",
    "            for prop in props:\n",
    "                values = graycoprops(glcm, prop)\n",
    "                features.extend(values.flatten())\n",
    "            features = np.array(features, dtype=np.float32)\n",
    "\n",
    "            # Normalisasi fitur (z-score)\n",
    "            features = (features - features.mean()) / (features.std() + 1e-8)\n",
    "            self.glcm_features.append(features)\n",
    "\n",
    "        # Konversi list ke tensor\n",
    "        self.glcm_features = torch.tensor(np.array(self.glcm_features), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
    "\n",
    "        print(\"âœ… GLCM features extracted and cached.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, _ = self.image_folder_dataset[index]  # label diambil dari self.labels\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        glcm_feature = self.glcm_features[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return image, glcm_feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preprocessing GLCM features...\n",
      "âœ… GLCM features extracted and cached.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Buat dataset dasar\n",
    "base_dataset = datasets.ImageFolder(root=datasets_path)\n",
    "hybrid_dataset = GLCMCNNHybridDataset(base_dataset, transform=transform)\n",
    "\n",
    "# Ambil semua label\n",
    "targets = base_dataset.targets\n",
    "indices = list(range(len(base_dataset)))\n",
    "\n",
    "# Pertama: Bagi data menjadi train+val dan test\n",
    "trainval_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=test_split_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ambil label untuk data trainval\n",
    "trainval_targets = [targets[i] for i in trainval_indices]\n",
    "\n",
    "# Kedua: Bagi trainval menjadi train dan val\n",
    "train_indices, val_indices = train_test_split(\n",
    "    trainval_indices,\n",
    "    test_size=val_split_ratio,\n",
    "    stratify=trainval_targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Buat subset dataset-nya\n",
    "train_dataset = Subset(hybrid_dataset, train_indices)\n",
    "val_dataset = Subset(hybrid_dataset, val_indices)\n",
    "test_dataset = Subset(hybrid_dataset, test_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape GLCM Features: torch.Size([16, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cek dimensi glcm_features\n",
    "for images, glcm_features, labels in train_loader:\n",
    "    print(\"Shape GLCM Features:\", glcm_features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas (train): Counter({1: 246, 0: 245})\n",
      "Distribusi kelas (test): Counter({0: 77, 1: 77})\n",
      "Distribusi kelas (val): Counter({0: 62, 1: 61})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Distribusi kelas (train):\", Counter([base_dataset.targets[i] for i in train_indices]))\n",
    "print(\"Distribusi kelas (test):\", Counter([base_dataset.targets[i] for i in test_indices]))\n",
    "print(\"Distribusi kelas (val):\", Counter([base_dataset.targets[i] for i in val_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model (EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet-B0\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "cnn_model = efficientnet_b0(weights=weights)\n",
    "cnn_feature_size = cnn_model.classifier[1].in_features  # EfficientNet features\n",
    "\n",
    "# Replace classification layer to get features\n",
    "cnn_model.classifier = nn.Identity()\n",
    "cnn_model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(cnn_feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PararelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(PararelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParallelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(SimpleParallelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 256)  # Menurunkan dimensi\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Langsung ke output class\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_feature_size = 60  # Number of GLCM features\n",
    "# model = PararelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)\n",
    "model = SimpleParallelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.4252, Val Acc: 0.9935\n",
      "Epoch [2/50], Loss: 0.1779, Val Acc: 0.9935\n",
      "Epoch [3/50], Loss: 0.0916, Val Acc: 0.9805\n",
      "Epoch [4/50], Loss: 0.1507, Val Acc: 0.9870\n",
      "Epoch [5/50], Loss: 0.0761, Val Acc: 0.9805\n",
      "Epoch [6/50], Loss: 0.0630, Val Acc: 0.9805\n",
      "Epoch [7/50], Loss: 0.0615, Val Acc: 0.9870\n",
      "Epoch [8/50], Loss: 0.0413, Val Acc: 0.9870\n",
      "Epoch [9/50], Loss: 0.0644, Val Acc: 0.9870\n",
      "Epoch [10/50], Loss: 0.0307, Val Acc: 0.9870\n",
      "Epoch [11/50], Loss: 0.0253, Val Acc: 0.9870\n",
      "Epoch [12/50], Loss: 0.0141, Val Acc: 0.9870\n",
      "Epoch [13/50], Loss: 0.0313, Val Acc: 0.9870\n",
      "Epoch [14/50], Loss: 0.0318, Val Acc: 0.9870\n",
      "Epoch [15/50], Loss: 0.0124, Val Acc: 0.9870\n",
      "Epoch [16/50], Loss: 0.0185, Val Acc: 0.9870\n",
      "Epoch [17/50], Loss: 0.0077, Val Acc: 0.9870\n",
      "Epoch [18/50], Loss: 0.0174, Val Acc: 0.9870\n",
      "Epoch [19/50], Loss: 0.0224, Val Acc: 0.9935\n",
      "Epoch [20/50], Loss: 0.0334, Val Acc: 0.9870\n",
      "Epoch [21/50], Loss: 0.0204, Val Acc: 0.9870\n",
      "Epoch [22/50], Loss: 0.0111, Val Acc: 0.9870\n",
      "â›” Early stopping triggered at epoch 22\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "patience = 5  # jumlah epoch tanpa perbaikan sebelum berhenti\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0015\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, glcm_features, labels in data_loader:\n",
    "            images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "            outputs = model(images, glcm_features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Training loop dengan early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, glcm_features, labels in train_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, glcm_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    val_acc = evaluate(model, test_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if epoch_loss < best_loss - 1e-4:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'temp/best_model_hybrid.pth')  # Simpan model terbaik\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"â›” Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  Precision: 0.9870\n",
      "  Recall:    0.9870\n",
      "  F1-Score:  0.9870\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision: 0.9870\n",
      "  Recall:    0.9870\n",
      "  F1-Score:  0.9870\n",
      "------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        77\n",
      "           1       0.99      0.99      0.99        77\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, glcm_features, labels in test_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "        outputs = model(images, glcm_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Hitung precision, recall, f1 untuk setiap kelas\n",
    "precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "\n",
    "# Tampilkan nilai precision, recall, dan f1-score per kelas\n",
    "num_classes = len(set(all_labels))  # Jumlah kelas yang ada di dataset\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall:    {recall[i]:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1[i]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Tampilkan classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), models_path+'/hybrid_glcm_cnn_modelv2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
