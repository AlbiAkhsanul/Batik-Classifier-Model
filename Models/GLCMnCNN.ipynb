{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()\n",
    "datasets_path = os.getenv('DATASET_PATH')\n",
    "models_path = os.getenv('MODELS_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 16\n",
    "test_split_ratio = 0.2\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "augment = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.3),\n",
    "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.05, 0.05), rotate=15, p=0.4)  # Pengganti ShiftScaleRotate\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset With GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "class GLCMCNNHybridDataset(Dataset):\n",
    "    def __init__(self, image_folder_dataset, transform=None, augment=None):\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def extract_glcm_features(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        distances = [1, 2, 3]\n",
    "        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "        glcm = graycomatrix(gray, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "        props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "        features = []\n",
    "\n",
    "        for prop in props:\n",
    "            values = graycoprops(glcm, prop)\n",
    "            features.extend(values.flatten())\n",
    "\n",
    "        return features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.image_folder_dataset[index]\n",
    "\n",
    "        if self.augment:\n",
    "            image_np = np.array(image)\n",
    "            image_np = self.augment(image=image_np)['image']\n",
    "            image = Image.fromarray(image_np)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert tensor to numpy image (H, W, C) for GLCM extraction\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        image_np = (image_np * 255).astype(np.uint8)\n",
    "\n",
    "        glcm_features = self.extract_glcm_features(image_np)\n",
    "        glcm_features = torch.tensor(glcm_features, dtype=torch.float32)\n",
    "        glcm_features = (glcm_features - glcm_features.mean()) / glcm_features.std()\n",
    "\n",
    "        return image, glcm_features, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Buat dataset dengan ImageFolder\n",
    "base_dataset = datasets.ImageFolder(root=datasets_path)\n",
    "\n",
    "# Bungkus dengan GLCMCNNHybridDataset\n",
    "hybrid_dataset = GLCMCNNHybridDataset(base_dataset, transform=transform, augment=augment)\n",
    "\n",
    "# Ambil semua label dari base_dataset untuk stratified split\n",
    "targets = base_dataset.targets  # Ini adalah daftar label (misal: [0, 1, 0, 1, ...])\n",
    "\n",
    "# Buat daftar semua indeks\n",
    "indices = list(range(len(base_dataset)))\n",
    "\n",
    "# Stratified split berdasarkan label\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=test_split_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Buat subset stratified dari hybrid_dataset\n",
    "train_dataset = Subset(hybrid_dataset, train_indices)\n",
    "test_dataset = Subset(hybrid_dataset, test_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape GLCM Features: torch.Size([16, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cek dimensi glcm_features\n",
    "for images, glcm_features, labels in train_loader:\n",
    "    print(\"Shape GLCM Features:\", glcm_features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas (train): Counter({0: 80, 1: 77})\n",
      "Distribusi kelas (test): Counter({0: 20, 1: 20})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Distribusi kelas (train):\", Counter([base_dataset.targets[i] for i in train_indices]))\n",
    "print(\"Distribusi kelas (test):\", Counter([base_dataset.targets[i] for i in test_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model (EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet-B0\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "cnn_model = efficientnet_b0(weights=weights)\n",
    "cnn_feature_size = cnn_model.classifier[1].in_features  # EfficientNet features\n",
    "\n",
    "# Replace classification layer to get features\n",
    "cnn_model.classifier = nn.Identity()\n",
    "cnn_model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(cnn_feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PararelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(PararelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParallelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(SimpleParallelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 256)  # Menurunkan dimensi\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Langsung ke output class\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_feature_size = 60  # Number of GLCM features\n",
    "# model = PararelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)\n",
    "model = SimpleParallelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6799\n",
      "Epoch [2/50], Loss: 0.6729\n",
      "Epoch [3/50], Loss: 0.6671\n",
      "Epoch [4/50], Loss: 0.6494\n",
      "Epoch [5/50], Loss: 0.6398\n",
      "Epoch [6/50], Loss: 0.6493\n",
      "Epoch [7/50], Loss: 0.6161\n",
      "Epoch [8/50], Loss: 0.6042\n",
      "Epoch [9/50], Loss: 0.6007\n",
      "Epoch [10/50], Loss: 0.5808\n",
      "Epoch [11/50], Loss: 0.5694\n",
      "Epoch [12/50], Loss: 0.5617\n",
      "Epoch [13/50], Loss: 0.5503\n",
      "Epoch [14/50], Loss: 0.5356\n",
      "Epoch [15/50], Loss: 0.5214\n",
      "Epoch [16/50], Loss: 0.5214\n",
      "Epoch [17/50], Loss: 0.4955\n",
      "Epoch [18/50], Loss: 0.4865\n",
      "Epoch [19/50], Loss: 0.4831\n",
      "Epoch [20/50], Loss: 0.4511\n",
      "Epoch [21/50], Loss: 0.4231\n",
      "Epoch [22/50], Loss: 0.4279\n",
      "Epoch [23/50], Loss: 0.4108\n",
      "Epoch [24/50], Loss: 0.4014\n",
      "Epoch [25/50], Loss: 0.3964\n",
      "Epoch [26/50], Loss: 0.3838\n",
      "Epoch [27/50], Loss: 0.3786\n",
      "Epoch [28/50], Loss: 0.3723\n",
      "Epoch [29/50], Loss: 0.3240\n",
      "Epoch [30/50], Loss: 0.3280\n",
      "Epoch [31/50], Loss: 0.3001\n",
      "Epoch [32/50], Loss: 0.3024\n",
      "Epoch [33/50], Loss: 0.3122\n",
      "Epoch [34/50], Loss: 0.2764\n",
      "Epoch [35/50], Loss: 0.2969\n",
      "Epoch [36/50], Loss: 0.2510\n",
      "Epoch [37/50], Loss: 0.3004\n",
      "Epoch [38/50], Loss: 0.2682\n",
      "Epoch [39/50], Loss: 0.2361\n",
      "Epoch [40/50], Loss: 0.2258\n",
      "Epoch [41/50], Loss: 0.2609\n",
      "Epoch [42/50], Loss: 0.2169\n",
      "Epoch [43/50], Loss: 0.2149\n",
      "Epoch [44/50], Loss: 0.1962\n",
      "Epoch [45/50], Loss: 0.1921\n",
      "Epoch [46/50], Loss: 0.1609\n",
      "Epoch [47/50], Loss: 0.2084\n",
      "Epoch [48/50], Loss: 0.1651\n",
      "Epoch [49/50], Loss: 0.1717\n",
      "Epoch [50/50], Loss: 0.1438\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "patience = 5  # jumlah epoch tanpa perbaikan sebelum berhenti\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.00001\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop dengan early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, glcm_features, labels in train_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, glcm_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if epoch_loss < best_loss - 1e-4:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Simpan model terbaik\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"â›” Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  Precision: 0.7619\n",
      "  Recall:    0.8000\n",
      "  F1-Score:  0.7805\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision: 0.7895\n",
      "  Recall:    0.7500\n",
      "  F1-Score:  0.7692\n",
      "------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        20\n",
      "           1       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJZdJREFUeJzt3QmY1WW9wPHfgIAI7siiuWHikvuSqSn6qOC1a6JXbTO31Cw1C3HhmimmUpm5J6biXlGaZlrhlgtmiSjmlmZgmoobigmJCHOf93/vzGXYHPwxcwbm83meeZjzP2fOec/YQ/8v7/v+T119fX19AAAAJHTI/DAAAEAhLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwA2pG//e1vMWDAgFh++eWjrq4ubr755kX6/M8//3z1vFddddUifd7F2U477VR9ASzphAVAK/v73/8eX/3qV6Nv376x9NJLx3LLLRfbb799nH/++fHvf/+7RV/7oIMOiscffzzOPPPMuPbaa2OrrbaKJcXBBx9cRU35fc7r91iiqtxfvn74wx8u9PO//PLLcdppp8X48eMX0YgBlixL1XoAAO3JbbfdFvvtt1906dIlDjzwwNhoo43i/fffjzFjxsTxxx8fTz75ZPzkJz9pkdcuJ9sPPvhgnHzyyXH00Ue3yGusueaa1et06tQpamGppZaKadOmxW9+85vYf//9m9x3/fXXVyH33nvvfaTnLmExbNiwWGuttWKzzTZr9s/dfvvtH+n1ABY3wgKglUycODE+//nPVyffd999d/Tp06fxvqOOOiqee+65Kjxayuuvv179ucIKK7TYa5TZgHLyXisl2Mrsz89+9rO5wuKnP/1pfOYzn4kbb7yxVcZSAmeZZZaJzp07t8rrAdSapVAAreQHP/hBvPvuu3HFFVc0iYoGH//4x+PYY49tvP3BBx/Ed7/73VhnnXWqE+byL+X//d//HdOnT2/yc+X4f/7nf1azHp/85CerE/uyzOqaa65pfExZwlOCpigzIyUAys81LCFq+H525WfK42Z3xx13xKc//ekqTrp37x7rrbdeNaYP22NRQmqHHXaIbt26VT+71157xdNPPz3P1yuBVcZUHlf2ghxyyCHVSXpzffGLX4zf/e538fbbbzceGzt2bLUUqtw3p8mTJ8eQIUNi4403rt5TWUr1H//xH/HYY481Puaee+6Jrbfeuvq+jKdhSVXD+yx7KMrs07hx42LHHXesgqLh9zLnHouyHK38N5rz/Q8cODBWXHHFamYEYHEkLABaSVmeU074t9tuu2Y9/rDDDovvfOc7scUWW8S5554b/fv3j+HDh1ezHnMqJ+P77rtv7LbbbnHOOedUJ6jl5LwsrSr22Wef6jmKL3zhC9X+ivPOO2+hxl+eqwRMCZvTTz+9ep3Pfvaz8cADDyzw5+68887qpPm1116r4mHw4MHxxz/+sZpZKCEypzLT8K9//at6r+X7cvJeliA1V3mv5aT/V7/6VZPZivXXX7/6Xc5pwoQJ1Sb28t5+9KMfVeFV9qGU33fDSf4GG2xQvefiiCOOqH5/5atERIM333yzCpKyTKr8bnfeeed5jq/spVlllVWqwJg5c2Z17NJLL62WTF144YWx6qqrNvu9ArQp9QC0uClTptSXv3L32muvZj1+/Pjx1eMPO+ywJseHDBlSHb/77rsbj6255prVsfvuu6/x2GuvvVbfpUuX+uOOO67x2MSJE6vHnX322U2e86CDDqqeY06nnnpq9fgG5557bnX79ddfn++4G17jyiuvbDy22Wab1ffs2bP+zTffbDz22GOP1Xfo0KH+wAMPnOv1Dj300CbPuffee9evvPLK833N2d9Ht27dqu/33Xff+l122aX6fubMmfW9e/euHzZs2Dx/B++99171mDnfR/n9nX766Y3Hxo4dO9d7a9C/f//qvhEjRszzvvI1u9GjR1ePP+OMM+onTJhQ37179/pBgwZ96HsEaMvMWAC0gnfeeaf6c9lll23W43/7299Wf5Z/3Z/dcccdV/05516MDTfcsFpq1KD8i3hZplT+NX5Radib8etf/zpmzZrVrJ955ZVXqqsoldmTlVZaqfH4JptsUs2uNLzP2R155JFNbpf3VWYDGn6HzVGWPJXlS5MmTaqWYZU/57UMqijLzDp0+N//OywzCOW1GpZ5PfLII81+zfI8ZZlUc5RL/pYrg5VZkDLDUpZGlVkLgMWZsABoBWXdflGW+DTHP/7xj+pkt+y7mF3v3r2rE/xy/+zWWGONuZ6jLId66623YlH53Oc+Vy1fKku0evXqVS3J+sUvfrHAyGgYZzlJn1NZXvTGG2/E1KlTF/heyvsoFua97LHHHlXEjRo1qroaVNkfMefvskEZf1kmtu6661Zx0KNHjyrM/vKXv8SUKVOa/ZqrrbbaQm3ULpe8LbFVwuuCCy6Inj17NvtnAdoiYQHQSmFR1s4/8cQTC/Vzc26enp+OHTvO83h9ff1Hfo2G9f8NunbtGvfdd1+1Z+LLX/5ydeJdYqPMPMz52IzMe2lQAqHMBFx99dVx0003zXe2ojjrrLOqmaGyX+K6666L0aNHV5vUP/GJTzR7Zqbh97MwHn300WrfSVH2dAAs7oQFQCspm4PLh+OVz5L4MOUKTuWktlzJaHavvvpqdbWjhis8LQplRmD2Kyg1mHNWpCizKLvssku1yfmpp56qPmivLDX6wx/+MN/3UTzzzDNz3ffXv/61mh0oV4pqCSUmysl7mSWa14b3BjfccEO10bpcras8rixT2nXXXef6nTQ38pqjzNKUZVNlCVvZDF6uGFauXAWwOBMWAK3khBNOqE6iy1KiEghzKtFRrhjUsJSnmPPKTeWEviifx7ColMvZliU/ZQZi9r0R5V/657ws65waPihuzkvgNiiX1S2PKTMHs5+ol5mbchWkhvfZEkoslMv1XnTRRdUSsgXNkMw5G/LLX/4yXnrppSbHGgJoXhG2sE488cR44YUXqt9L+W9aLvdbrhI1v98jwOLAB+QBtJJyAl8ue1qWD5X9BbN/8na5/Go5mS2bnItNN920OtEsn8JdTmTLpU8feuih6kR00KBB872U6UdR/pW+nOjuvffe8Y1vfKP6zIhLLrkk+vXr12TzctloXJZClagpMxFlGc+Pf/zj+NjHPlZ9tsX8nH322dVlWLfddtv4yle+Un0yd7msavmMinL52ZZSZle+/e1vN2smqby3MoNQLgVcliWVfRnl0sBz/vcr+1tGjBhR7d8oobHNNtvE2muvvVDjKjM85fd26qmnNl7+9sorr6w+6+KUU06pZi8AFkdmLABaUfnchzIzUD5zolxdqXzi9kknnVR9nkP5XIiyibfB5ZdfXn1+Q1ki881vfrM6IR06dGj8/Oc/X6RjWnnllavZifKhbmVWpcRL+QyJPffcc66xl43VI0eOrMZ98cUXV/sSyrhKJMxPWVb0+9//vnqd8rkcZdPypz71qerzLxb2pLwllA+yK1fbKnsrygcUlpgqV91affXVmzyuU6dO1e+mzHCUK1eVzwO59957F+q1yrKsQw89NDbffPM4+eSTm1z5qrx2+d/An/70p0X23gBaU1255myrviIAALDEMWMBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJC2RH7ydtfNj671EABohrfGXlTrIQDwIZZuZjGYsQAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExbQhmy/xTpxw3lfjQm3nxn/fvSi2HOnTeZ6zHpr94pfnvfVmHTf2fHGH8+JMdcdH6v3XrEm4wVgbldc9pPY9BPrxQ+Gn1nroUCrWqp1Xw5YkG5du8Tjz74U1/z6wRj1oyPmun/tj/WIu0YOjqtv/mOccclt8c7U92LDdfrEe9Nn1GS8ADT1xON/iRt++fPo12+9Wg8FWp2wgDbk9geeqr7mZ9jRe8boMU/Gyef/uvHYxH++0UqjA2BBpk2dGkNPPD5OHXZGXHbpJbUeDrQ6S6FgMVFXVxe7f/oT8bcXXotbLj4q/nHX8LjvmiHzXC4FQOs764zTY8cd+8entt2u1kOB9jdj8cYbb8TIkSPjwQcfjEmTJlXHevfuHdttt10cfPDBscoqq9RyeNCm9FypeyzbbekYcshuMeziW+Pb598cA7bfMH5+zmEx8IgLYsy452o9RIB263e/vS2efvqp+OmoG2o9FGh/YTF27NgYOHBgLLPMMrHrrrtGv379quOvvvpqXHDBBfG9730vRo8eHVtttdUCn2f69OnV1+zqZ82Mug4dW3T80No6dPjfCcZb73k8Lrz+D9X3f3n2pdhm075x+L6fFhYANTLplVfiB987My69bGR06dKl1sOB9hcWxxxzTOy3334xYsSIaonH7Orr6+PII4+sHlNmMxZk+PDhMWzYsCbHOvbaOjr1+WSLjBtq5Y233o0ZM2bG0xNeaXL8mQmTYrvN+9ZsXADt3VNPPRmT33wzPr/fPo3HZs6cGeMeHhs//9n1MfbRx6NjR//gyZKvZmHx2GOPxVVXXTVXVBTl2Le+9a3YfPPNP/R5hg4dGoMHD25yrOcOJy7SsUJbMOODmTHuqX9EvzV7NTm+7po944VX3qrZuADau20+9am44ebfNDl26slDY62+feOQrxwuKmg3ahYWZS/FQw89FOuvv/487y/39erV9ARqXsqU45zTjpZBsbjq1rVzrLP6/+8tWmu1lWOTfqvFW+9MixcnvRXnXn1nXPv9Q2PMI8/FvQ8/GwO22zD22HGjGHj4+TUdN0B71q1b91h33f9d0t2g6zLLxArLrzDXcViS1SwshgwZEkcccUSMGzcudtlll8aIKHss7rrrrrjsssvihz/8Ya2GBzWxxYZrxu2XH9t4+wdD/qv689pb/hRHnHpd3PKHv8QxZ/48jj90QJxzwr7x7D9eiy8cf3n8cfyEGo4aACCirr5saKiRUaNGxbnnnlvFRVmLWJTpwi233LJa3rT//vt/pOftuvnRi3ikALSEt8ZeVOshAPAhll5qMQiLBjNmzKguPVv06NEjOnXqlHo+YQGweBAWAEtOWLSJT94uIdGnT59aDwMAAPiIfPI2AACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACA2oTF/fffHwcccEBsu+228dJLL1XHrr322hgzZkx+RAAAwJIfFjfeeGMMHDgwunbtGo8++mhMnz69Oj5lypQ466yzWmKMAADAkhYWZ5xxRowYMSIuu+yy6NSpU+Px7bffPh555JFFPT4AAGBJDItnnnkmdtxxx7mOL7/88vH2228vqnEBAABLclj07t07nnvuubmOl/0Vffv2XVTjAgAAluSwOPzww+PYY4+NP//5z1FXVxcvv/xyXH/99TFkyJD42te+1jKjBAAA2rSlFvYHTjrppJg1a1bssssuMW3atGpZVJcuXaqwOOaYY1pmlAAAQJtWV19fX/9RfvD999+vlkS9++67seGGG0b37t2jrei6+dG1HgIAzfDW2ItqPQQAPsTSS7XQjEWDzp07V0EBAACw0GGx8847V3sr5ufuu+/OjgkAAFjSw2KzzTZrcnvGjBkxfvz4eOKJJ+Kggw5alGMDAACW1LA499xz53n8tNNOq/ZbAAAA7c9CX252fg444IAYOXLkono6AACgPYbFgw8+GEsvvfSiejoAAGBJXgq1zz77NLldrlb7yiuvxMMPPxynnHJKtAUT75n3ci0A2pYVP/PDWg8BgA/x79FDokXCYvnll29yu0OHDrHeeuvF6aefHgMGDFjYpwMAAJYACxUWM2fOjEMOOSQ23njjWHHFFVtuVAAAwJK7x6Jjx47VrMTbb7/dciMCAACW/M3bG220UUyYMKFlRgMAALSPsDjjjDNiyJAhceutt1abtt95550mXwAAQPvT7D0WZXP2cccdF3vssUd1+7Of/WzU1dU1uTpUuV32YQAAAO1LXX0pgmburygzFE8//fQCH9e/f/+otUlTZtR6CAA0w9r7n1/rIQDQ2pebbeiPthAOAADAYrzHYvalTwAAAB/pcyz69ev3oXExefLkhXlKAACgvYXFsGHD5vrkbQAAgIUKi89//vPRs2fPlhsNAACwZO+xsL8CAABIh0Uzr0oLAAC0Q81eCjVr1qyWHQkAANA+LjcLAAAwL8ICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBtqfxTAC3lyp9cHFddfkmTY2usuXZc+8vf1GxMAO3d9ht9LL6139axxbq9os/K3WP/026O3zz4XOP9Pzlu9/jygI2a/MztD0+MvU6+sQajhdYjLKCNW7vvx+Ociy5vvN1xqY41HQ9Ae9dt6U7x+ITX4prRj8eoUwfN8zGjx06Mr57zu8bb02fMbMURQm0IC2jjOnbsGCv36FHrYQAw2+xD+VqQ92d8EK++Na3VxgRtgbCANu6fL74Q++yxc3Tu3CU+sfGmccRR34xevfvUelgALMAOm6we/xj19Xj7X+/FPY+9EMOuGhOT//VerYcF7Xfz9osvvhiHHnporYcBNbPBRpvESd85I84+f0QMPvGUeOXlf8YxRxwY06ZOrfXQAJiPOx6eGIed/bvY48RfxLevuC922Hj1+PWZ/xUdOtTVemjQfmcsJk+eHFdffXWMHDlyvo+ZPn169dX0WIfo0qVLK4wQWtanttuh8ft11l0vNtho4/jcZwfEH+78fXxmr/+q6dgAmLdf3vtM4/dPPv9GPD7x9Xj66sNjx01Wj3vGv1DTscESGxa33HLLAu+fMGHChz7H8OHDY9iwYU2OHXfit2PI0O+kxwdtzbLLLhcfW2PNeOmf/o8JYHHx/KQp8frb02KdVVcQFizRahoWgwYNirq6uqivr5/vY8r9CzJ06NAYPHhwk2NvvdemV3jBRzZt2rR4+aUXY6Uee9Z6KAA002o9usfKy3WNSZMtY2XJVtOw6NOnT/z4xz+Ovfbaa573jx8/PrbccssFPkdZ8jTnsqdp9TMW6TihVn58/tmx3Q47Ra/eq8abb7wWI39ycXTo0DF2HbBHrYcG0K4vN1tmHxqs1Xv52KTvKvHWv96rNmiffMB2cfOYZ2PSW1Ojb58V4szDdoy/v/xW3DHu+ZqOG5bosCjRMG7cuPmGxYfNZsCS7vXXXo3Tv31CvDPl7VhhxZVi4003j0tGXl99D0BtbNGvd9x+9ucab//gyJ2rP6+9/Yn4xoV3xkZr94gv7faJWKFbl3jlzXfjzkeej9OvfiDe91kWLOHq6mt45n7//ffH1KlTY/fdd5/n/eW+hx9+OPr3779QzztpihkLgMXB2vufX+shAPAh/j16SLT5GYsddvj/K97MS7du3RY6KgAAgNZnlzMAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADShAUAAJAmLAAAgDRhAQAApAkLAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAkCYsAACANGEBAACkCQsAACBNWAAAAGnCAgAASBMWAABAmrAAAADS6urr6+vzTwO0pOnTp8fw4cNj6NCh0aVLl1oPB4B58Hc17Z2wgMXAO++8E8svv3xMmTIllltuuVoPB4B58Hc17Z2lUAAAQJqwAAAA0oQFAACQJixgMVA2AZ566qk2AwK0Yf6upr2zeRsAAEgzYwEAAKQJCwAAIE1YAAAAacIC2riLL7441lprrVh66aVjm222iYceeqjWQwJgNvfdd1/sueeeseqqq0ZdXV3cfPPNtR4S1ISwgDZs1KhRMXjw4OoqI4888khsuummMXDgwHjttddqPTQA/s/UqVOrv5/LPwRBe+aqUNCGlRmKrbfeOi666KLq9qxZs2L11VePY445Jk466aRaDw+AOZQZi5tuuikGDRpU66FAqzNjAW3U+++/H+PGjYtdd9218ViHDh2q2w8++GBNxwYAMCdhAW3UG2+8ETNnzoxevXo1OV5uT5o0qWbjAgCYF2EBAACkCQtoo3r06BEdO3aMV199tcnxcrt37941GxcAwLwIC2ijOnfuHFtuuWXcddddjcfK5u1ye9ttt63p2AAA5rTUXEeANqNcavaggw6KrbbaKj75yU/GeeedV13W8JBDDqn10AD4P++++24899xzjbcnTpwY48ePj5VWWinWWGONmo4NWpPLzUIbVy41e/bZZ1cbtjfbbLO44IILqsvQAtA23HPPPbHzzjvPdbz8w9BVV11VkzFBLQgLAAAgzR4LAAAgTVgAAABpwgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwBa3MEHHxyDBg1qvL3TTjvFN7/5zZp8QnJdXV28/fbbrf7aAEs6YQHQzk/4y4l2+ercuXN8/OMfj9NPPz0++OCDFn3dX/3qV/Hd7363WY8VAwCLh6VqPQAAamv33XePK6+8MqZPnx6//e1v46ijjopOnTrF0KFDmzzu/fffr+JjUVhppZUWyfMA0HaYsQBo57p06RK9e/eONddcM772ta/FrrvuGrfcckvj8qUzzzwzVl111VhvvfWqx7/44oux//77xworrFAFwl577RXPP/984/PNnDkzBg8eXN2/8sorxwknnBD19fVNXnPOpVAlak488cRYffXVq/GUmZMrrriiet6dd965esyKK65YzVyUcRWzZs2K4cOHx9prrx1du3aNTTfdNG644YYmr1NCqV+/ftX95XlmHycAi5awAKCJchJeZieKu+66K5555pm444474tZbb40ZM2bEwIEDY9lll437778/HnjggejevXs169HwM+ecc05cddVVMXLkyBgzZkxMnjw5brrppgW+5oEHHhg/+9nP4oILLoinn346Lr300up5S2jceOON1WPKOF555ZU4//zzq9slKq655poYMWJEPPnkk/Gtb30rDjjggLj33nsbA2ifffaJPffcM8aPHx+HHXZYnHTSSS382wNovyyFAqBSZhVKSIwePTqOOeaYeP3116Nbt25x+eWXNy6Buu6666qZgnKszB4UZRlVmZ0oeyEGDBgQ5513XrWMqpzUF+XEvzzn/Dz77LPxi1/8ooqXMltS9O3bd65lUz179qxep2GG46yzzoo777wztt1228afKSFToqR///5xySWXxDrrrFOFTlFmXB5//PH4/ve/30K/QYD2TVgAtHNlJqLMDpTZiBINX/ziF+O0006r9lpsvPHGTfZVPPbYY/Hcc89VMxaze++99+Lvf/97TJkypZpV2GabbRrvW2qppWKrrbaaazlUgzKb0LFjxyoGmquMYdq0abHbbrs1OV5mTTbffPPq+zLzMfs4ioYIAWDRExYA7VzZe1D+db8ERNlLUUKgQZmxmN27774bW265ZVx//fVzPc8qq6zykZdeLawyjuK2226L1VZbrcl9ZY8GAK1PWAC0cyUeymbp5thiiy1i1KhR1bKk5ZZbbp6P6dOnT/z5z3+OHXfcsbpdLl07bty46mfnpcyKlJmSsjeiYSnU7BpmTMqm8AYbbrhhFRAvvPDCfGc6Nthgg2oT+uz+9Kc/Net9ArDwbN4GoNm+9KUvRY8ePaorQZXN2xMnTqz2VnzjG9+If/7zn9Vjjj322Pje974XN998c/z1r3+Nr3/96wv8DIq11lorDjrooDj00EOrn2l4zrLvoihXqyr7OcqSrbLvo8xWlKVYQ4YMqTZsX3311dUyrEceeSQuvPDC6nZx5JFHxt/+9rc4/vjjq43fP/3pT6tN5QC0DGEBQLMts8wycd9998Uaa6xRbc4uswJf+cpXqj0WDTMYxx13XHz5y1+uYqHsaSgRsPfeey/wectSrH333beKkPXXXz8OP/zwmDp1anVfWeo0bNiw6opOvXr1iqOPPro6Xj5g75RTTqmuDlXGUa5MVZZGlcvPFmWM5YpSJVbKpWjLJvKy4RuAllFXP7/ddAAAAM1kxgIAAEgTFgAAQJqwAAAA0oQFAACQJiwAAIA0YQEAAKQJCwAAIE1YAAAAacICAABIExYAAECasAAAANKEBQAAEFn/A3M/YJIKyJwdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, glcm_features, labels in test_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "        outputs = model(images, glcm_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Hitung precision, recall, f1 untuk setiap kelas\n",
    "precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "\n",
    "# Tampilkan nilai precision, recall, dan f1-score per kelas\n",
    "num_classes = len(set(all_labels))  # Jumlah kelas yang ada di dataset\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall:    {recall[i]:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1[i]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Tampilkan classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'hybrid_glcm_cnn_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
