{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()\n",
    "datasets_path = os.getenv('DATASET_PATH')\n",
    "models_path = os.getenv('MODELS_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 16\n",
    "test_split_ratio = 0.2\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset With GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLCMCNNHybridDataset(Dataset):\n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def extract_glcm_features(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        features = [\n",
    "            graycoprops(glcm, 'contrast')[0, 0],\n",
    "            graycoprops(glcm, 'dissimilarity')[0, 0],\n",
    "            graycoprops(glcm, 'homogeneity')[0, 0],\n",
    "            graycoprops(glcm, 'energy')[0, 0],\n",
    "            graycoprops(glcm, 'correlation')[0, 0],\n",
    "        ]\n",
    "        return features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.image_folder_dataset[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert tensor to numpy image (H, W, C) for GLCM extraction\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        image_np = (image_np * 255).astype(np.uint8)\n",
    "\n",
    "        glcm_features = self.extract_glcm_features(image_np)\n",
    "        glcm_features = torch.tensor(glcm_features, dtype=torch.float32)\n",
    "\n",
    "        return image, glcm_features, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Buat dataset dengan ImageFolder\n",
    "base_dataset = datasets.ImageFolder(root=datasets_path)\n",
    "\n",
    "# Bungkus dengan GLCMCNNHybridDataset\n",
    "hybrid_dataset = GLCMCNNHybridDataset(base_dataset, transform=transform)\n",
    "\n",
    "# Ambil semua label dari base_dataset untuk stratified split\n",
    "targets = base_dataset.targets  # Ini adalah daftar label (misal: [0, 1, 0, 1, ...])\n",
    "\n",
    "# Buat daftar semua indeks\n",
    "indices = list(range(len(base_dataset)))\n",
    "\n",
    "# Stratified split berdasarkan label\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=test_split_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Buat subset stratified dari hybrid_dataset\n",
    "train_dataset = Subset(hybrid_dataset, train_indices)\n",
    "test_dataset = Subset(hybrid_dataset, test_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas (train): Counter({0: 80, 1: 77})\n",
      "Distribusi kelas (test): Counter({0: 20, 1: 20})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Distribusi kelas (train):\", Counter([base_dataset.targets[i] for i in train_indices]))\n",
    "print(\"Distribusi kelas (test):\", Counter([base_dataset.targets[i] for i in test_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model (EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet-B0\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "cnn_model = efficientnet_b0(weights=weights)\n",
    "cnn_feature_size = cnn_model.classifier[1].in_features  # EfficientNet features\n",
    "\n",
    "# Replace classification layer to get features\n",
    "cnn_model.classifier = nn.Identity()\n",
    "cnn_model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PararelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(PararelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParallelModel(nn.Module):\n",
    "    def __init__(self, cnn_model, glcm_feature_size, cnn_feature_size, num_classes):\n",
    "        super(SimpleParallelModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.fc1 = nn.Linear(glcm_feature_size + cnn_feature_size, 256)  # Menurunkan dimensi\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # Langsung ke output class\n",
    "\n",
    "    def forward(self, image, glcm_features):\n",
    "        cnn_features = self.cnn_model(image)\n",
    "        combined_features = torch.cat((glcm_features, cnn_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_feature_size = 5  # Number of GLCM features\n",
    "# model = PararelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)\n",
    "model = SimpleParallelModel(cnn_model, glcm_feature_size, cnn_feature_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 4.4920\n",
      "Epoch [2/50], Loss: 3.9132\n",
      "Epoch [3/50], Loss: 2.5579\n",
      "Epoch [4/50], Loss: 1.1072\n",
      "Epoch [5/50], Loss: 1.3745\n",
      "Epoch [6/50], Loss: 0.9911\n",
      "Epoch [7/50], Loss: 0.8535\n",
      "Epoch [8/50], Loss: 1.0466\n",
      "Epoch [9/50], Loss: 1.0813\n",
      "Epoch [10/50], Loss: 0.8993\n",
      "Epoch [11/50], Loss: 1.7607\n",
      "Epoch [12/50], Loss: 1.3878\n",
      "⛔ Early stopping triggered at epoch 12\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "patience = 5  # jumlah epoch tanpa perbaikan sebelum berhenti\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.000001\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop dengan early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, glcm_features, labels in train_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, glcm_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if epoch_loss < best_loss - 1e-4:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Simpan model terbaik\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"⛔ Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "  Precision: 0.5000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  0.6667\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, glcm_features, labels in test_loader:\n",
    "        images, glcm_features, labels = images.to(device), glcm_features.to(device), labels.to(device)\n",
    "        outputs = model(images, glcm_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Hitung precision, recall, f1 untuk setiap kelas\n",
    "precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "\n",
    "# Tampilkan nilai precision, recall, dan f1-score per kelas\n",
    "num_classes = len(set(all_labels))  # Jumlah kelas yang ada di dataset\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall:    {recall[i]:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1[i]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Tampilkan classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'hybrid_glcm_cnn_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
